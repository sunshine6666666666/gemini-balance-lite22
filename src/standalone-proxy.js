/**
 * ç‹¬ç«‹ä»£ç† - å®Œå…¨è‡ªåŒ…å«ï¼Œæ— å¤–éƒ¨ä¾èµ–
 * ç”¨äºæµ‹è¯•Edge Runtimeå…¼å®¹æ€§
 */

/**
 * ä¸»è¯·æ±‚å¤„ç†å‡½æ•°
 */
export async function handleRequest(request) {
  const reqId = Date.now().toString();
  console.log(`[${reqId}] è¯·æ±‚å¼€å§‹: ${request.method} ${new URL(request.url).pathname}`);
  
  try {
    const url = new URL(request.url);
    
    // å¤„ç†CORSé¢„æ£€è¯·æ±‚
    if (request.method === 'OPTIONS') {
      console.log(`[${reqId}] CORSé¢„æ£€è¯·æ±‚`);
      return new Response(null, { 
        status: 200,
        headers: {
          'Access-Control-Allow-Origin': '*',
          'Access-Control-Allow-Methods': 'GET, POST, PUT, DELETE, OPTIONS',
          'Access-Control-Allow-Headers': 'Content-Type, Authorization'
        }
      });
    }

    // å¤„ç†é¦–é¡µè®¿é—®
    if (url.pathname === '/' || url.pathname === '/index.html') {
      console.log(`[${reqId}] é¦–é¡µè®¿é—®`);
      return new Response('Proxy is Running! Standalone Version', {
        status: 200,
        headers: { 'Content-Type': 'text/plain; charset=utf-8' }
      });
    }

    // å¤„ç†OpenAIå…¼å®¹è¯·æ±‚
    if (url.pathname.startsWith('/v1/')) {
      console.log(`[${reqId}] OpenAIå…¼å®¹è¯·æ±‚`);
      return handleOpenAIRequest(request, reqId);
    }

    // å…¶ä»–è¯·æ±‚
    console.log(`[${reqId}] æœªçŸ¥è¯·æ±‚`);
    return new Response('Not Found', { status: 404 });
    
  } catch (error) {
    console.log(`[${reqId}] é”™è¯¯: ${error.message}`);

    // ğŸ” è¯¦ç»†è®°å½•ä¸»é”™è¯¯ä¿¡æ¯
    console.log(`âŒ [${reqId}] === ä¸»é”™è¯¯å¤„ç†è¯¦æƒ… ===`);
    console.log(`ğŸ“ [${reqId}] é”™è¯¯ç±»å‹: ${error.constructor.name}`);
    console.log(`ğŸ“ [${reqId}] é”™è¯¯æ¶ˆæ¯: ${error.message}`);
    if (error.stack) {
      console.log(`ğŸ“ [${reqId}] é”™è¯¯å †æ ˆ:`);
      console.log(error.stack);
    }

    const errorResponse = {
      error: {
        message: error.message,
        type: "proxy_error",
        timestamp: new Date().toISOString(),
        requestId: reqId
      }
    };

    // ğŸ” è¯¦ç»†è®°å½•é”™è¯¯å“åº”ä½“
    console.log(`ğŸ“¤ [${reqId}] === é”™è¯¯å“åº”ä½“è¯¦æƒ… ===`);
    console.log(`ğŸ“ [${reqId}] é”™è¯¯å“åº”ä½“ (æ ¼å¼åŒ–):`);
    console.log(JSON.stringify(errorResponse, null, 2));

    return new Response(JSON.stringify(errorResponse), {
      status: 500,
      headers: { 'Content-Type': 'application/json' }
    });
  }
}

/**
 * å¤„ç†OpenAIå…¼å®¹è¯·æ±‚
 */
async function handleOpenAIRequest(request, reqId) {
  const url = new URL(request.url);
  
  // è·å–API Key
  const auth = request.headers.get("Authorization");
  const apiKey = auth?.split(" ")[1];
  if (!apiKey) {
    throw new Error('ç¼ºå°‘API Key');
  }
  
  console.log(`[${reqId}] API Key: ${apiKey.substring(0, 8)}...`);

  // è·¯ç”±å¤„ç†
  if (url.pathname.endsWith("/chat/completions")) {
    console.log(`[${reqId}] èŠå¤©å®Œæˆè¯·æ±‚`);
    const chatBody = await request.json();
    return handleChatCompletions(chatBody, apiKey, reqId);
  }

  if (url.pathname.endsWith("/models")) {
    console.log(`[${reqId}] æ¨¡å‹åˆ—è¡¨è¯·æ±‚`);
    return handleModels(reqId);
  }

  throw new Error(`ä¸æ”¯æŒçš„ç«¯ç‚¹: ${url.pathname}`);
}

/**
 * å¤„ç†èŠå¤©å®Œæˆè¯·æ±‚
 */
async function handleChatCompletions(openaiRequest, apiKey, reqId) {
  console.log(`[${reqId}] å¼€å§‹æ ¼å¼è½¬æ¢`);

  // ğŸ” è¯¦ç»†è®°å½•OpenAIè¯·æ±‚ä½“ - é«˜å¯è¯»æ€§JSON
  console.log(`ğŸ“¥ [${reqId}] === OpenAIè¯·æ±‚ä½“è¯¦æƒ… ===`);
  console.log(`ğŸ“ [${reqId}] OpenAIè¯·æ±‚ä½“ (æ ¼å¼åŒ–):`);
  console.log(JSON.stringify(openaiRequest, null, 2));
  console.log(`ğŸ“Š [${reqId}] è¯·æ±‚ä½“å¤§å°: ${JSON.stringify(openaiRequest).length} å­—ç¬¦`);

  // è½¬æ¢æ¶ˆæ¯æ ¼å¼
  const geminiContents = openaiRequest.messages.map(msg => ({
    role: msg.role === 'assistant' ? 'model' : msg.role,
    parts: [{ text: msg.content }]
  }));

  // æ„å»ºGeminiè¯·æ±‚
  const geminiRequest = {
    contents: geminiContents,
    generationConfig: {
      temperature: openaiRequest.temperature || 0.7,
      maxOutputTokens: openaiRequest.max_tokens || 1024,
      topP: openaiRequest.top_p || 1.0
    }
  };

  console.log(`[${reqId}] è½¬æ¢å®Œæˆ: ${geminiContents.length}æ¡æ¶ˆæ¯`);

  // ğŸ” è¯¦ç»†è®°å½•Geminiè¯·æ±‚ä½“ - é«˜å¯è¯»æ€§JSON
  console.log(`ğŸ“¤ [${reqId}] === Geminiè¯·æ±‚ä½“è¯¦æƒ… ===`);
  console.log(`ğŸ“ [${reqId}] Geminiè¯·æ±‚ä½“ (æ ¼å¼åŒ–):`);
  console.log(JSON.stringify(geminiRequest, null, 2));
  console.log(`ğŸ“Š [${reqId}] è¯·æ±‚ä½“å¤§å°: ${JSON.stringify(geminiRequest).length} å­—ç¬¦`);

  // å‘é€è¯·æ±‚åˆ°Gemini
  const model = 'gemini-2.5-flash';
  const targetUrl = `https://generativelanguage.googleapis.com/v1beta/models/${model}:generateContent?key=${apiKey}`;

  console.log(`[${reqId}] å‘é€åˆ°Gemini: ${model}`);

  try {
    const response = await fetch(targetUrl, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify(geminiRequest)
    });

    if (!response.ok) {
      throw new Error(`Gemini APIé”™è¯¯: ${response.status}`);
    }

    const geminiResponse = await response.json();
    console.log(`[${reqId}] Geminiå“åº”æˆåŠŸ`);

    // ğŸ” è¯¦ç»†è®°å½•Geminiå“åº”ä½“ - é«˜å¯è¯»æ€§JSON
    console.log(`ğŸ“¥ [${reqId}] === Geminiå“åº”ä½“è¯¦æƒ… ===`);
    console.log(`ğŸ“ [${reqId}] Geminiå“åº”ä½“ (æ ¼å¼åŒ–):`);
    console.log(JSON.stringify(geminiResponse, null, 2));
    console.log(`ğŸ“Š [${reqId}] å“åº”ä½“å¤§å°: ${JSON.stringify(geminiResponse).length} å­—ç¬¦`);

    // è½¬æ¢ä¸ºOpenAIæ ¼å¼
    const openaiResponse = {
      id: `chatcmpl-${reqId}`,
      object: "chat.completion",
      created: Math.floor(Date.now() / 1000),
      model: "gpt-3.5-turbo",
      choices: [{
        index: 0,
        message: {
          role: "assistant",
          content: geminiResponse.candidates?.[0]?.content?.parts?.[0]?.text || "æŠ±æ­‰ï¼Œæ— æ³•ç”Ÿæˆå›å¤ã€‚"
        },
        finish_reason: "stop"
      }],
      usage: {
        prompt_tokens: 0,
        completion_tokens: 0,
        total_tokens: 0
      }
    };

    console.log(`[${reqId}] æ ¼å¼è½¬æ¢å®Œæˆ`);

    // ğŸ” è¯¦ç»†è®°å½•OpenAIå“åº”ä½“ - é«˜å¯è¯»æ€§JSON
    console.log(`ğŸ“¤ [${reqId}] === OpenAIå“åº”ä½“è¯¦æƒ… ===`);
    console.log(`ğŸ“ [${reqId}] OpenAIå“åº”ä½“ (æ ¼å¼åŒ–):`);
    console.log(JSON.stringify(openaiResponse, null, 2));
    console.log(`ğŸ“Š [${reqId}] å“åº”ä½“å¤§å°: ${JSON.stringify(openaiResponse).length} å­—ç¬¦`);

    return new Response(JSON.stringify(openaiResponse), {
      status: 200,
      headers: { 
        'Content-Type': 'application/json',
        'Access-Control-Allow-Origin': '*'
      }
    });

  } catch (error) {
    console.log(`[${reqId}] Geminiè¯·æ±‚å¤±è´¥: ${error.message}`);

    // ğŸ” è¯¦ç»†è®°å½•é”™è¯¯ä¿¡æ¯
    console.log(`âŒ [${reqId}] === é”™è¯¯è¯¦æƒ… ===`);
    console.log(`ğŸ“ [${reqId}] é”™è¯¯ç±»å‹: ${error.constructor.name}`);
    console.log(`ğŸ“ [${reqId}] é”™è¯¯æ¶ˆæ¯: ${error.message}`);
    if (error.stack) {
      console.log(`ğŸ“ [${reqId}] é”™è¯¯å †æ ˆ:`);
      console.log(error.stack);
    }

    throw error;
  }
}

/**
 * å¤„ç†æ¨¡å‹åˆ—è¡¨è¯·æ±‚
 */
function handleModels(reqId) {
  console.log(`[${reqId}] è¿”å›æ¨¡å‹åˆ—è¡¨`);
  
  const models = {
    object: "list",
    data: [
      { id: "gpt-3.5-turbo", object: "model", created: 1677610602, owned_by: "openai" },
      { id: "gpt-4", object: "model", created: 1687882411, owned_by: "openai" },
      { id: "gemini-2.5-flash", object: "model", created: 1687882411, owned_by: "google" },
      { id: "gemini-2.5-pro", object: "model", created: 1687882411, owned_by: "google" }
    ]
  };

  return new Response(JSON.stringify(models), {
    status: 200,
    headers: { 
      'Content-Type': 'application/json',
      'Access-Control-Allow-Origin': '*'
    }
  });
}
